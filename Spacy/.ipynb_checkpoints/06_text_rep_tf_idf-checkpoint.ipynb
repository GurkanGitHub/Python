{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "There is no need today to labor the point that a scientific approach does not\n",
    "consist solely, or even mainly, in a complete system and a comprehensive\n",
    "doctrine. In the formal sense the present work contains no such svstem;\n",
    "instead of a complete theory it offers only material for one.\n",
    "\"\"\"\n",
    "text = text.replace(\"\\n\", \" \").rstrip(\" \").lstrip(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.fit([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'there': 37,\n",
       " 'is': 13,\n",
       " 'no': 19,\n",
       " 'need': 18,\n",
       " 'today': 39,\n",
       " 'to': 38,\n",
       " 'labor': 15,\n",
       " 'the': 35,\n",
       " 'point': 26,\n",
       " 'that': 34,\n",
       " 'scientific': 28,\n",
       " 'approach': 1,\n",
       " 'does': 7,\n",
       " 'not': 20,\n",
       " 'consist': 4,\n",
       " 'solely': 30,\n",
       " 'or': 25,\n",
       " 'even': 8,\n",
       " 'mainly': 16,\n",
       " 'in': 11,\n",
       " 'complete': 2,\n",
       " 'system': 33,\n",
       " 'and': 0,\n",
       " 'comprehensive': 3,\n",
       " 'doctrine': 6,\n",
       " 'formal': 10,\n",
       " 'sense': 29,\n",
       " 'present': 27,\n",
       " 'work': 40,\n",
       " 'contains': 5,\n",
       " 'such': 31,\n",
       " 'svstem': 32,\n",
       " 'instead': 12,\n",
       " 'of': 21,\n",
       " 'theory': 36,\n",
       " 'it': 14,\n",
       " 'offers': 22,\n",
       " 'only': 24,\n",
       " 'material': 17,\n",
       " 'for': 9,\n",
       " 'one': 23}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    filtered_tokens= []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "        \n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = preprocessing(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.fit([clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'need': 11,\n",
       " 'today': 21,\n",
       " 'labor': 8,\n",
       " 'point': 13,\n",
       " 'scientific': 15,\n",
       " 'approach': 0,\n",
       " 'consist': 3,\n",
       " 'solely': 17,\n",
       " 'mainly': 9,\n",
       " 'complete': 1,\n",
       " 'system': 19,\n",
       " 'comprehensive': 2,\n",
       " 'doctrine': 5,\n",
       " 'formal': 6,\n",
       " 'sense': 16,\n",
       " 'present': 14,\n",
       " 'work': 22,\n",
       " 'contain': 4,\n",
       " 'svstem': 18,\n",
       " 'instead': 7,\n",
       " 'theory': 20,\n",
       " 'offer': 12,\n",
       " 'material': 10}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform([clean]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = doc.count_by(spacy.attrs.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(95, 2), (87, 2), (90, 9), (92, 11), (94, 2), (100, 4), (98, 1), (84, 7), (86, 5), (97, 5), (89, 2), (85, 4), (93, 1)])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IS_ALPHA'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vocab[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRON | 2\n",
      "AUX | 2\n",
      "DET | 9\n",
      "NOUN | 11\n",
      "PART | 2\n",
      "VERB | 4\n",
      "SCONJ | 1\n",
      "ADJ | 7\n",
      "ADV | 5\n",
      "PUNCT | 5\n",
      "CCONJ | 2\n",
      "ADP | 4\n",
      "NUM | 1\n"
     ]
    }
   ],
   "source": [
    "for k,v in count.items():\n",
    "    print(doc.vocab[k].text, \"|\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = [token.text for token in doc if not token.is_stop and not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_tokens= {}\n",
    "for token in clean:\n",
    "    if token not in freq_tokens:\n",
    "        freq_tokens[token] = 1\n",
    "    else:\n",
    "        freq_tokens[token] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('need', 1), ('today', 1), ('labor', 1), ('point', 1), ('scientific', 1), ('approach', 1), ('consist', 1), ('solely', 1), ('mainly', 1), ('complete', 2), ('system', 1), ('comprehensive', 1), ('doctrine', 1), ('formal', 1), ('sense', 1), ('present', 1), ('work', 1), ('contains', 1), ('svstem', 1), ('instead', 1), ('theory', 1), ('offers', 1), ('material', 1)])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tokens.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['need', 'today', 'labor', 'point', 'scientific', 'approach', 'consist', 'solely', 'mainly', 'complete', 'system', 'comprehensive', 'doctrine', 'formal', 'sense', 'present', 'work', 'contains', 'svstem', 'instead', 'theory', 'offers', 'material'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complete'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(freq_tokens.keys(), key=(lambda key: freq_tokens[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
