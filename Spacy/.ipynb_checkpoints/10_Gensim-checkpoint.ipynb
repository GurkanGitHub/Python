{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api# importing appropriate word vectors\n",
    "\n",
    "wv = api.load(\"word2vec-google-news-300\") # specify what kind of word embedding to get\n",
    "                # one of the word embeddings that available is a model that is trained on Google News. \n",
    "                # there are trained word vectors available in internet. \n",
    "        # and different librarires like sPacy, Gensim, Pytorch, you can load those vectors, \n",
    "        #when you talk about word2vec and glove, these are two different appraches or algorithms to word embeddings.  these algorithms are trained on either in Google news, or twitter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All gensim models are listed on this page: https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.729151"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1=\"great\", w2=\"good\") # similiary concept in word embedding is based on the context they appear not on synonyms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34199455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1=\"profit\", w2= \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28772825"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1=\"profit\", w2= \"gain\")#sometimesi t gives counter ntuitive results, but they appear in same context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.7291510105133057),\n",
       " ('bad', 0.7190051078796387),\n",
       " ('terrific', 0.6889115571975708),\n",
       " ('decent', 0.6837348341941833),\n",
       " ('nice', 0.6836092472076416),\n",
       " ('excellent', 0.644292950630188),\n",
       " ('fantastic', 0.6407778263092041),\n",
       " ('better', 0.6120728850364685),\n",
       " ('solid', 0.5806034803390503),\n",
       " ('lousy', 0.576420247554779)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"good\") # good and bad appear in similar context: I was ffeling good or bad since it was holiday or monday. Structures are similar so they get high value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dogs', 0.8680489659309387),\n",
       " ('puppy', 0.8106428384780884),\n",
       " ('pit_bull', 0.780396044254303),\n",
       " ('pooch', 0.7627376914024353),\n",
       " ('cat', 0.7609457969665527),\n",
       " ('golden_retriever', 0.7500901818275452),\n",
       " ('German_shepherd', 0.7465174198150635),\n",
       " ('Rottweiler', 0.7437615394592285),\n",
       " ('beagle', 0.7418621778488159),\n",
       " ('pup', 0.740691065788269)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wars', 0.748465895652771),\n",
       " ('War', 0.6410670280456543),\n",
       " ('invasion', 0.5892109870910645),\n",
       " ('Persian_Gulf_War', 0.5890660285949707),\n",
       " ('Vietnam_War', 0.5886474847793579),\n",
       " ('Iraq', 0.5885995030403137),\n",
       " ('unwinnable_quagmire', 0.5681803226470947),\n",
       " ('un_winnable', 0.5606350302696228),\n",
       " ('occupation', 0.5506216883659363),\n",
       " ('conflict', 0.5506188869476318)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"war\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "France -Paris + Berlin = Germany, calculations in gensim is more convenient than sPacy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.5094343423843384),\n",
       " ('european', 0.48650455474853516),\n",
       " ('german', 0.4714890420436859),\n",
       " ('austria', 0.46964022517204285),\n",
       " ('swedish', 0.4645182490348816),\n",
       " ('Wissenschaft', 0.4532880485057831),\n",
       " ('denmark', 0.4477355182170868),\n",
       " ('MÃ¼nchen', 0.4438532590866089),\n",
       " ('europe', 0.4420619308948517),\n",
       " ('belgium', 0.43769752979278564)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive = [\"france\", \"berlin\"], negative = [\"paris\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match([\"facebook\", \"cat\", \"google\", \"microsoft\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "glv = api.load(\"glove-twitter-25\")#glove-twitter-25 is trained on 2b tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('too', 0.9648017287254333),\n",
       " ('day', 0.9533665180206299),\n",
       " ('well', 0.9503170847892761),\n",
       " ('nice', 0.9438973665237427),\n",
       " ('better', 0.9425962567329407),\n",
       " ('fun', 0.9418926239013672),\n",
       " ('much', 0.9413353800773621),\n",
       " ('this', 0.9387555122375488),\n",
       " ('hope', 0.9383506774902344),\n",
       " ('great', 0.9378516674041748)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('an', 0.8172838687896729),\n",
       " ('man', 0.8146011829376221),\n",
       " ('land', 0.8118465542793274),\n",
       " ('in', 0.8102032542228699),\n",
       " ('also', 0.7996509075164795),\n",
       " ('of', 0.7946149706840515),\n",
       " ('hunger', 0.7906949520111084),\n",
       " ('death', 0.7895672917366028),\n",
       " ('over', 0.7804927229881287),\n",
       " ('is', 0.774983286857605)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.most_similar(\"war\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
